# GPTPerEval - Summarization

## Install Required Packages

!pip -q install sentencepiece

!pip install -q rouge-score

!pip install -qU datasets

!pip install -q openai==0.28

## Persian Abstractive/Extractive Text Summarization `pn_summary` Dataset

import random
import time
import numpy as np
import pandas as pd
from IPython import display
from datasets import load_dataset

from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
from rouge_score import rouge_scorer

data = load_dataset("pn_summary")

print(data)

# test_data = data['test']

# # Set the seed for reproducibility
# random.seed(21)  # You can use any number as the seed

# # Randomly select 200 indices
# sample_indices = random.sample(range(len(test_data)), 200)

# # Select 200 samples using these indices
# sample_data = test_data.select(sample_indices)

# # Remove unwanted columns
# columns_to_remove = ['id', 'title', 'category', 'categories', 'network', 'link']
# reduced_dataset = sample_data.remove_columns(columns_to_remove)

# reduced_dataset

test_data = data['test']

# Example: Filter out articles with more than 500 words
filtered_data = test_data.filter(lambda example: len(example['article'].split()) <= 500)

# Set the seed for reproducibility
random.seed(21)  # You can use any number as the seed

# Randomly select 200 indices from the filtered dataset
sample_indices = random.sample(range(len(filtered_data)), min(200, len(filtered_data)))

# Select 200 samples using these indices
sample_data = filtered_data.select(sample_indices)

# Remove unwanted columns
columns_to_remove = ['id', 'title', 'category', 'categories', 'network', 'link']
reduced_dataset = sample_data.remove_columns(columns_to_remove)

reduced_dataset

df = pd.DataFrame(reduced_dataset)
df

len(df['article'][0].split())

# Calculate average word count for articles
df['article_word_count'] = df['article'].apply(lambda x: len(x.split()))
average_article_word_count = df['article_word_count'].mean()

# Calculate average word count for summaries
df['summary_word_count'] = df['summary'].apply(lambda x: len(x.split()))
average_summary_word_count = df['summary_word_count'].mean()

# Calculate average token count for articles
df['article_token_count'] = df['article'].apply(lambda x: len(tokenizer.tokenize(x)))
average_article_token_count = df['article_token_count'].mean()

# Calculate average token count for summaries
df['summary_token_count'] = df['summary'].apply(lambda x: len(tokenizer.tokenize(x)))
average_summary_token_count = df['summary_token_count'].mean()

print(f"Average article word count: {average_article_word_count}")
print(f"Average summary word count: {average_summary_word_count}")
print(f"Average article token count: {average_article_token_count}")
print(f"Average summary token count: {average_summary_token_count}")

# Assuming df is your DataFrame with 'article' and 'summary' columns
# Calculate the word count for each article and summary
df['article_word_count'] = df['article'].apply(lambda x: len(x.split()))
df['summary_word_count'] = df['summary'].apply(lambda x: len(x.split()))

# Calculate mean, min, and max for articles
article_mean_length = df['article_word_count'].mean()
article_min_length = df['article_word_count'].min()
article_max_length = df['article_word_count'].max()

# Calculate mean, min, and max for summaries
summary_mean_length = df['summary_word_count'].mean()
summary_min_length = df['summary_word_count'].min()
summary_max_length = df['summary_word_count'].max()

print(f"Articles - Mean Length: {article_mean_length}, Min Length: {article_min_length}, Max Length: {article_max_length}")
print(f"Summaries - Mean Length: {summary_mean_length}, Min Length: {summary_min_length}, Max Length: {summary_max_length}")

## Info.


# import openai
# openai.api_key  = "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"

# def get_completion(prompt, model="gpt-3.5-turbo"): # Andrew mentioned that the prompt/ completion paradigm is preferable for this class
#     messages = [{"role": "user", "content": prompt}]
#     response = openai.ChatCompletion.create(
#         model=model,
#         messages=messages,
#         temperature=0, # this is the degree of randomness of the model's output
#     )
#     return response.choices[0].message["content"]

# def get_completion_from_messages(messages, model="gpt-3.5-turbo", temperature=0):
#     response = openai.ChatCompletion.create(
#         model=model,
#         messages=messages,
#         temperature=temperature, # this is the degree of randomness of the model's output
#     )
# #     print(str(response.choices[0].message))
#     return response.choices[0].message["content"]

# prompt = f"""
# Your task is to generate a concise summary of the news articles provided by various news agencies.

# Summarize each news article below in Persian language, which is delimited by triple backticks, in at most 30 words to capture the essential information, main events, and significant points of interest.
# Please ensure the summary is accurate, neutral, and devoid of personal opinions or interpretations.

# Artcile: ```{df_1}```
# """

# prompt_x = f"""
# Your task is to generate a concise summary of the news articles provided by various news agencies.

# Summarize each news article below in Persian language, which is delimited by triple backticks, in at most 30 words.
# Please ensure the summary is accurate, neutral, and devoid of personal opinions or interpretations.

# Artcile: ```{df_1}```
# """

# prompt_xx = f"""
# Your task is to generate a concise summary of the news articles provided by various news agencies.

# Summarize each news article below in Persian language, which is delimited by triple backticks, in at most 30 words.

# Artcile: ```{df_1}```
# """

# response = get_completion(prompt)
# print(response)



# import openai
# import os

# openai.api_key  = "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"

# # It's safer to get the API key from an environment variable or a secure key vault.
# # openai.api_key = os.getenv('OPENAI_API_KEY')

# def get_completion(prompt, model="gpt-3.5-turbo", temperature=0):
#     try:
#         messages = [{"role": "user", "content": prompt}]
#         response = openai.ChatCompletion.create(
#             model=model,
#             messages=messages,
#             temperature=temperature, # Degree of randomness in the model's output
#         )
#         return response.choices[0].message["content"]
#     except Exception as e:
#         print(f"An error occurred: {e}")
#         return None

# def get_summary(df_content, model="gpt-3.5-turbo", temperature=0):
#     prompt = f"""
#     Your task is to generate a concise summary of the news articles provided by various news agencies.

#     Summarize each news article below in Persian language, which is delimited by triple backticks, in at most 30 words.
#     Please ensure the summary is accurate, neutral, and devoid of personal opinions or interpretations.

#     Artcile: ```{df_content}```
#     """
#     return get_completion(prompt, model=model, temperature=temperature)

# # # Assuming df_1 is a string that contains the content of the news article.
# # # If df_1 is a DataFrame, you'll need to convert it to a string that contains the news content.
# # df_1_content = "The content of your news article goes here."
# # summary = get_summary(df_1_content, model="gpt-4")  # Assuming you want to use the latest model
# # print(summary)

# import openai
# import os

# openai.api_key  = "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"

# # It's safer to get the API key from an environment variable or a secure key vault.
# # openai.api_key = os.getenv('OPENAI_API_KEY')

# def get_completion(prompt, model="gpt-3.5-turbo", temperature=0):
#     try:
#         messages = [{"role": "user", "content": prompt}]
#         response = openai.ChatCompletion.create(
#             model=model,
#             messages=messages,
#             temperature=temperature, # Degree of randomness in the model's output
#         )
#         return response.choices[0].message["content"]
#     except Exception as e:
#         print(f"An error occurred: {e}")
#         return None

# def get_summary(article_content, model="gpt-3.5-turbo", temperature=0):
#     prompt = f"""
#     Your task is to generate a concise summary of the following news article in Persian language, in at most 30 words to capture the essential information, main events, and significant points of interest.
#     Please ensure the summary is accurate, neutral, and devoid of personal opinions or interpretations.

#     Article: ```{article_content}```
#     """
#     response = openai.Completion.create(
#         engine=model,
#         prompt=prompt,
#         max_tokens=60,  # Adjust based on how long you expect the summaries to be
#         temperature=temperature
#     )
#     return response.choices[0].text.strip()

# get_summary(df.iloc[0], model="gpt-3.5-turbo", temperature=0)

# # Select the first row of the DataFrame using iloc
# row = df.iloc[0]

# # Get the summary for the article in the first row
# # summary = get_summary(row['article'])

# # Iterate over the DataFrame and apply the summarization model to each article
# summaries = []
# for index, row in df.iloc[0].iterrows():
#     summary = get_summary(row['article'])
#     summaries.append(summary)

# # Add the summaries as a new column to the DataFrame
# df['summary'] = summaries

## OpenAI

import openai

# Function to get summary using the chat completion model
def get_summary(article_content, model="gpt-3.5-turbo", temperature=0):
    # Make sure you're using the appropriate API call for a chat model
    prompt = f"""
    Your task is to generate a concise summary of the following news article in Persian language, in at most 30 words to capture the essential information, main events, and significant points of interest.
    Please ensure the summary is accurate, neutral, and devoid of personal opinions or interpretations.

    Article: ```{article_content}```
    """
    response = openai.ChatCompletion.create(
        model=model,
        messages=[{"role": "system", "content": "You are a language model trained to summarize news articles concisely and accurately."},
                  {"role": "user", "content": prompt}],
        temperature=temperature
    )
    summary = response.choices[0].message['content']
    return summary.strip()  # Strip to remove any extra whitespace

df_3 = df[:3]

# Iterate over the DataFrame and apply the summarization model to each article
summaries = []
for index, row in df_3.iterrows():
    summary = get_summary(row['article'])
    print(summary)
    summaries.append(summary)
    time.sleep(22)

# print(summaries)

# Add the summaries as a new column to the DataFrame
# df['summary'] = summaries

# Save the updated DataFrame to a new CSV file
df.to_csv('updated_dataset_with_summaries.csv', index=False)



## MT5

### token = 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

!huggingface-cli login

# !pip install tokenizers

# Load model directly
tokenizer = AutoTokenizer.from_pretrained("HooshvareLab/pn-summary-mt5-base")
model = AutoModelForSeq2SeqLM.from_pretrained("HooshvareLab/pn-summary-mt5-base")

# # Assuming df is your DataFrame and it has 'article' and 'reference_summary' columns
# generated_summaries = []
# for article in df['article']:
#     inputs = tokenizer(article, return_tensors="pt", max_length=512, truncation=True)
#     summary_ids = model.generate(inputs['input_ids'], max_length=150, length_penalty=2.0, num_beams=4, early_stopping=True)
#     summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
#     generated_summaries.append(summary)

# # Add the generated summaries to the DataFrame
# df['generated_summary_mt5'] = generated_summaries

df.head()

# Assuming df is your DataFrame
if 'generated_summary' not in df.columns:
    df['generated_summary'] = None  # Initialize the column with None or ''

total_articles = len(df['article'])
print("Starting summarization process...")
print("-"*50)
last_percentage_reported = -1

for i, row in df.iterrows():
    # Check if the summary for this row is already generated
    if pd.isna(row['generated_summary']):
        # Tokenize the article
        inputs = tokenizer(row['article'], return_tensors="pt", max_length=512, truncation=True)

        # Generate summary
        summary_ids = model.generate(inputs['input_ids'], max_length=128, length_penalty=2.0, num_beams=4, early_stopping=True)
        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)

        # Update the DataFrame
        df.at[i, 'generated_summary'] = summary

        # Calculate and print the progress at each percentage point
        percent_done = (i + 1) / total_articles * 100
        if int(percent_done) > last_percentage_reported:
            print(f"{int(percent_done)}% done ({i + 1}/{total_articles} articles summarized)")
            last_percentage_reported = int(percent_done)

        # Optional: Save progress every 10 summaries
        if i % 10 == 0:
            df.to_csv(f'summary_progress_step{i/200}.csv', index=False)

# Save the final DataFrame
df.to_csv('final_summary_mt5.csv', index=False)

# # Assuming df is your DataFrame and it has 'article' columns
# generated_summaries = []

# total_articles = len(df['article'])
# print("Starting summarization process...")

# last_percentage_reported = -1

# for i, article in enumerate(df['article']):
#     inputs = tokenizer(article, return_tensors="pt", max_length=512, truncation=True)
#     summary_ids = model.generate(inputs['input_ids'], max_length=128, length_penalty=2.0, num_beams=4, early_stopping=True)
#     summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)
#     generated_summaries.append(summary)

#     # Calculate and print the progress at each percentage point
#     percent_done = (i + 1) / total_articles * 100
#     if int(percent_done) > last_percentage_reported:
#         print(f"{int(percent_done)}% done ({i + 1}/{total_articles} articles summarized)")
#         last_percentage_reported = int(percent_done)

# # Add the generated summaries to the DataFrame
# df['generated_summary_mt5'] = generated_summaries

# Save the updated DataFrame to a new CSV file
df.to_csv('summary_mt5.csv', index=False)

## Evaluation

### OpenAI

# scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)

# # Calculate ROUGE scores
# rouge_scores = []
# for reference, generated in zip(df['summary'], df['generated_summary_openai']):
#     score = scorer.score(reference, generated)
#     rouge_scores.append(score)

# # Add ROUGE scores to the DataFrame
# df['rouge_scores'] = rouge_scores

# # To get the average score over the dataset:
# average_scores = {
#     'rouge1': np.mean([score['rouge1'].fmeasure for score in rouge_scores]),
#     'rouge2': np.mean([score['rouge2'].fmeasure for score in rouge_scores]),
#     'rougeL': np.mean([score['rougeL'].fmeasure for score in rouge_scores]),
# }

# print(average_scores)

### MT5

df

import numpy as np
from rouge_score import rouge_scorer

scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)

# Checking for empty strings
empty_ref = df['summary'].eq('').sum()
empty_gen = df['generated_summary'].eq('').sum()
print(f"Empty reference summaries: {empty_ref}, Empty generated summaries: {empty_gen}")

# Print some sample summaries for inspection
for i in range(5):
    print(f"Reference: {df['summary'][i]}")
    print(f"Generated: {df['generated_summary'][i]}")
    print('-'*50)

# Calculate ROUGE scores
rouge_scores = []
for reference, generated in zip(df['summary'], df['generated_summary']):
    score = scorer.score(reference, generated)
    rouge_scores.append(score)

# Calculate and print average scores
average_scores = {
    'rouge1': np.mean([score['rouge1'].fmeasure for score in rouge_scores]),
    'rouge2': np.mean([score['rouge2'].fmeasure for score in rouge_scores]),
    'rougeL': np.mean([score['rougeL'].fmeasure for score in rouge_scores]),
}
print(average_scores)

scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)

# Calculate ROUGE scores
rouge_scores = []
for reference, generated in zip(df['summary'], df['generated_summary']):
    score = scorer.score(reference, generated)
    rouge_scores.append(score)

# Add ROUGE scores to the DataFrame
df['rouge_scores'] = rouge_scores

# To get the average score over the dataset:
average_scores = {
    'rouge1': np.mean([score['rouge1'].fmeasure for score in rouge_scores]),
    'rouge2': np.mean([score['rouge2'].fmeasure for score in rouge_scores]),
    'rougeL': np.mean([score['rougeL'].fmeasure for score in rouge_scores]),
}

print(average_scores)

scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)

# Calculate ROUGE scores
rouge_scores = []
for reference, generated in zip(df['summary'], df['generated_summary_mt5']):
    score = scorer.score(reference, generated)
    rouge_scores.append(score)

# Add ROUGE scores to the DataFrame
df['rouge_scores'] = rouge_scores

# To get the average score over the dataset:
average_scores = {
    'rouge1': np.mean([score['rouge1'].fmeasure for score in rouge_scores]),
    'rouge2': np.mean([score['rouge2'].fmeasure for score in rouge_scores]),
    'rougeL': np.mean([score['rougeL'].fmeasure for score in rouge_scores]),
}

print(average_scores)
